# -*- coding: utf-8 -*-
"""ScrapyDataBasic_BaqueroSebastian_S10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SRYQO_lbVniA4fNUufKakJCr-leJrVJC
"""

# Instalar librerías necesarias
!pip install beautifulsoup4 requests pandas

# Importar librerías necesarias
import requests
import pandas as pd
from bs4 import BeautifulSoup as bs
from tabulate import tabulate

# Función para procesar los datos de la tabla en HTML
def processTableData(tbl):
    rows = []
    for row in tbl.find('tbody').find_all('tr'):  # Itera sobre cada fila de la tabla
        cells = [cell.text.strip() for cell in row.find_all(['td', 'th'])]  # Extrae el texto de cada celda
        if cells:
            rows.append(cells)
    return rows

# Leer el sitio web
url = 'https://es.wikipedia.org/wiki/Anexo:Tabla_histórica_de_la_Copa_Libertadores'
response = requests.get(url)

if response.status_code == 200:
    soup = bs(response.content, 'html.parser')
    table = soup.find_all('table')[0]  # Ajustar el índice si es necesario
    # Extraer los datos de la tabla y convertirlos en un DataFrame
    table_data = processTableData(table)
    df = pd.DataFrame(table_data[1:], columns=table_data[0])  # Usa la primera fila como encabezado
    
    # Presentación de la tabla en consola
    print("Tabla de Copas Libertadores:")
    print(tabulate(df.head(20), headers='keys', tablefmt='fancy_grid', showindex=False))

    # Guardar en un archivo CSV
    df.to_csv('copaLibertadores.csv', index=False)
    print("\nArchivo CSV guardado con éxito.")

else:
    print(f"Error: No se pudo acceder al sitio web. Código de estado {response.status_code}")
